---
title: "NMDS for detritus"
author: "Sari Giering (10 Dec 2021)"
output:
  html_document: 
    keep_md: no
  pdf_document: default
  word_document: default
editor_options: 
  chunk_output_type: console
---

### File version history

# Background
Most of the images collected by the Plankton Imager are of detritus.
Detritus is difficult to categorise by humans,
and in this dataset, no further classification had been carried out for detritus.
We will hence explore whether we can use clustering to find groups of detritus that are similar,
and which could be used environmental mapping.

I originally wanted to use NMDS here - similar to what I did with the zooplankton data.
However, NMDS is computationally too slow for the large 'long' dataset we have (40,000 rows).
I therefore suggest that we use a PCA. I am not as familiar with the math behind the PCA,
but it should be OK for our purposes for now.

Here a link to a nice summary of ordination methods: 
https://ourcodingclub.github.io/tutorials/ordination/



# Data
I load the low-level data from ecotaxa here.

```{r load_data}
  # define project root
  library(here)
  i_am("notebooks/R/2021-12-09 NMDS for detritus.Rmd")

  # load low-level features
  dat <- read.table(here("data", "processed", "low_features", "ecotaxa_export-david.tsv"), comment.char = "[", header = T)
```
   
```{r label1} 
  # ---- add label1 ----
  
  # read index file
  index_all <- read.csv(here("data", "raw", "index.csv"), header = TRUE)

  # tidy file name
  dat$filename1 <- sub("0-", "", dat$img_file_name)
  dat$filename <-  sub("-[0-9].tif", ".tif", dat$filename1)

  # check that matching is complete
  table(dat$filename %in% index_all$filename)
  
  # add label1
  dat$label1 <- index_all$label1[match(dat$filename, index_all$filename)]
  
  # only keep detritus
  detr <- dat[dat$label1 %in% "detritus",]
  
  # extract data for NMDS (only numerical data allowed)
  detr_mat <- detr[, -which(names(detr) %in% c("object_label", "img_file_name", "img_rank", "filename1", "filename", "label1"))]

  # rename columns for easier readability
  NAMES       <- names(detr_mat)
  NAMES_SHORT <- sub("object_", "", names(detr_mat))
  colnames(detr_mat) <- NAMES_SHORT
  
  # remove columns with constant value (i.e 0 variance)
  detr_mat <- detr_mat[, apply(detr_mat, 2, var, na.rm=TRUE) != 0]
```

## NMDS

```{r nmds}
  library(vegan)
  
  # take subset
  mat <- detr_mat[seq(1, 40000, by = 20), ]

  # calculate dissimilarities (on 1:10)
  detr_mds <- metaMDS(mat, k = 2, try = 1, trymax = 1)

    # stress < 0.2 is good.
  
  # check
  detr_mds
  
  # plot coordination
  plot(detr_mds, type = 'n')
  points(detr_mds, display = "site")
  
  plot(detr_mds, type = 'n')
  text(detr_mds, display = "species", col = 3, cex = 0.8)
```

```{r clustering}
  library(factoextra)

  # make distance matrix (same transformation as for metaMDS)
  dist <- vegdist(wisconsin(sqrt(mat)))
  
```

```{r bb_code}
  mat_scaled <- wisconsin(sqrt(mat))
  
  par(mfrow=c(2,3))
  for(i in 1:26) hist(mat_scaled[, i], main = i)
  summary(mat_scaled)

  # initial look for clusters (hierarchical)
  library(factoextra)
  hc_cut <- hcut(mat_scaled, k = 6, hc_method = "average")
  
  fviz_cluster(hc_cut)
  fviz_cluster(hc_cut, axes = c(1, 3))
  fviz_cluster(hc_cut, axes = c(2, 3))
  
  library(rgl)
  res_pca <- FactoMineR::PCA(mat_scaled)
  
  # visualize eigenvalues/variances
  library(factoextra)
  fviz_screeplot(res_pca, addlabels = TRUE)
  
  # extrac the results for variables
  #var <- get_pca_var(res_pca)
  
  # contributions of varoables to PC1
  fviz_contrib(res_pca, choice = "var", axes = 1)
  fviz_contrib(res_pca, choice = "var", axes = 2)
  fviz_contrib(res_pca, choice = "var", axes = 3)

  
  # plot individuals
  fviz_pca_ind(res_pca)
  
  # elbow method
  fviz_nbclust(mat_scaled, kmeans, method = "wss", k.max = 12)

  # k_means
  k_mat <- kmeans(mat_scaled, 5)
  fviz_cluster(k_mat, mat_scaled)
  fviz_cluster(k_mat, mat_scaled, axes = c(2, 3))
  fviz_cluster(k_mat, mat_scaled, axes = c(1, 3))

  library(dplyr)
  View(as.data.frame(mat) %>% mutate(Cluster = k_mat$cluster) %>% group_by(Cluster) %>% summarize_all("mean"))
    
  plot3d(res_pca$ind$coord[, 1:3], col = scales::hue_pal()(4)[k_mat$cluster], type = 's')
  


```
